{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bba6933e",
   "metadata": {},
   "source": [
    "# 3. Dimensionality reduction\n",
    "\n",
    "This tutorial on reducing the dimension of the scattering coefficients using an\n",
    "independent component analysis. In this Jupyter notebook, we will walk through\n",
    "the process of extracting the most relevant features in order to use them later\n",
    "for clustering. We here follow again the indications in Steinmann et al.\n",
    "([2021](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2021JB022455))\n",
    "but we advise that many other methods for reducing the dimensions may be\n",
    "relevant for other datasets. \n",
    "\n",
    "Made in 2022 by René Steinmann and Léonard Seydoux."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "713f93cf",
   "metadata": {},
   "source": [
    "This notebook uses the __matplotlib__ and __scikit-learn__ library, please run the cell below if the packages are not installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2f5ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc24ead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "plt.rcParams[\"date.converter\"] = \"concise\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db10ba58",
   "metadata": {},
   "source": [
    "## Load scattering coefficients\n",
    "\n",
    "First, we load the scattering coefficients and reshape them for any [dimensionality reduction](https://scikit-learn.org/stable/modules/unsupervised_reduction.html) model (here `FastICA`) of the `scikit-learn` package. The shape of the scattering coefficients are given by the following tuples:\n",
    "\n",
    "- Order 1: `(n_times, n_channel, octaves[0] * resolution[0])`\n",
    "- Order 2: `(n_times, n_channel, octaves[0] * octaves[1] * resolution[0]  *\n",
    "  resolution[1])`\n",
    "- ...\n",
    "- Order n: `(n_times, n_channel, np.prod(octaves) * np.prod(resolution))`\n",
    "\n",
    "We then need to collect the all-order scattering coefficients into a\n",
    "two-dimensional matrix for use with Scikit Learn. \n",
    "\n",
    "> Note that the optimal way to load the scattering coefficients is to use `xarray` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c652505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from file\n",
    "with np.load(\"../example/scattering_coefficients.npz\", allow_pickle=True) as data:\n",
    "    order_1 = data[\"order_1\"]\n",
    "    order_2 = data[\"order_2\"]\n",
    "    times = data[\"times\"]\n",
    "\n",
    "# Reshape and stack scattering coefficients of all orders\n",
    "order_1 = order_1.reshape(order_1.shape[0], -1)\n",
    "order_2 = order_2.reshape(order_2.shape[0], -1)\n",
    "scattering_coefficients = np.hstack((order_1, order_2))\n",
    "# print(scattering_coefficients)\n",
    "\n",
    "# transform into log\n",
    "scattering_coefficients = np.log(scattering_coefficients)\n",
    "\n",
    "# print info about shape\n",
    "n_times, n_coeff = scattering_coefficients.shape\n",
    "print(\"Collected {} samples of {} dimensions each.\".format(n_times, n_coeff))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23596a99",
   "metadata": {},
   "source": [
    "## Extract independant features\n",
    "\n",
    "After loading and stacking the scattering coefficients into a matrix, we can now apply a dimentionality reduction algorithm. We here use the `FastICA` algorithm, but highly recommend to try other algorithms that will allow to proceed in the most adapted way to the data at hand. \n",
    "\n",
    "The `FastICA` algorithm looks for a matrix factorization with independent sources, and a mixing matrix. We need to inform the model about how many components (or features) we want to extract in the `n_components` keyword argument  below. The residual shape of the `features` matrix will be `(n_times, n_components)` instead of the initial scattering coefficients shape shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a45695",
   "metadata": {},
   "outputs": [],
   "source": [
    "scattering_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd1a9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastICA(n_components=10, whiten=\"unit-variance\")\n",
    "features = model.fit_transform(scattering_coefficients)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e10dd0df",
   "metadata": {},
   "source": [
    "### Save the output\n",
    "\n",
    "We here save the extracted features scattering coefficients as a npz-file, like the scattering coefficients in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8807de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the features\n",
    "np.savez(\n",
    "    \"../example/independent_components.npz\",\n",
    "    features=features,\n",
    "    times=times,\n",
    ")\n",
    "\n",
    "# Save the dimension reduction model\n",
    "with open(\"../example/dimension_model.pickle\", \"wb\") as pickle_file:\n",
    "    pickle.dump(\n",
    "        model,\n",
    "        pickle_file,\n",
    "        protocol=pickle.HIGHEST_PROTOCOL,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61e9cf9f",
   "metadata": {},
   "source": [
    "### Have a look at the features\n",
    "\n",
    "This is a crucial step: do you see structure in the independent components, or do they seem all random? Do the structures correlate with the a priori information at your disposal or to identifiable signal structures? At this stage, it is important to carefully address those questions. The optimal solution may not be to use the `FastICA` model depending on the data at hand, although it can be adapated to many datasets. Playing with the number of components can also be an immportant way of creating structure in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fd1443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features for display\n",
    "features_normalized = features / np.abs(features).max(axis=0)\n",
    "\n",
    "# Figure instance\n",
    "fig = plt.figure(dpi=200)\n",
    "ax = plt.axes()\n",
    "\n",
    "# Plot features\n",
    "ax.plot(times, features_normalized + np.arange(features.shape[1]), rasterized=True)\n",
    "\n",
    "# Labels\n",
    "ax.set_ylabel(\"Feature index\")\n",
    "ax.set_xlabel(\"Date and time\")\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552d4506",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scatseisnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "ff40ac3a3ffdf777b2291a6e55c1e0c401660695396eac1c1a92baa29c863b6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
